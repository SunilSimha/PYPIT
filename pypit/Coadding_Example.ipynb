{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import quad\n",
    "from scipy import interpolate\n",
    "from astropy.io import fits\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "sns.axes_style(\"darkgrid\")\n",
    "from MeasureFlux import FindCentroidX,gaussian, ShiftData, ShiftDataX\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from shutil import copyfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coadding Example: Flexure correction (wavelength shifting), Spatial shifting, then run through DCR cosmic ray removal, finally coadd\n",
    "\n",
    "Note that this is for LowRedux reduced LRIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, shift the data to correct for the flexure and spatial dithering during the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4  4  2  0 -1 -1 -3 -4]\n"
     ]
    }
   ],
   "source": [
    "centroids2 = np.array([2488,2488,2488,2486,2484,2483,2483,2481,2480])\n",
    "centroid_shifts2 = centroids2-centroids2[4]\n",
    "print centroid_shifts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12. -12. -12. -11. -12. -12. -12. -13. -13.]\n",
      "[ 12.  12.  12.  11.  12.  12.  12.  13.  13.]\n"
     ]
    }
   ],
   "source": [
    "flexshift_1d = np.array([-12.16,-11.98,-11.66,-11.36,-11.70,-12.20,-12.46,-12.86,-13.10])\n",
    "print np.round(flexshift_1d )\n",
    "angperpix_1d = 0.256418793232\n",
    "angperpix_2d = 0.258\n",
    "flexshift_2d = -1*np.round((flexshift_1d*angperpix_1d)/angperpix_2d)\n",
    "#the -1 is because of the definition of the shift value --> tested the other way around, was wrong, so need the -1\n",
    "print flexshift_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "refname = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science','sci-b150909_1092.fits')\n",
    "hdulistref = fits.open(refname)\n",
    "for fn in xrange(len(filenames)):\n",
    "    \n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug',filenames[fn])\n",
    "    \n",
    "    # copy the original file to shifted directory\n",
    "    copyname = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',filenames[fn])\n",
    "    copyfile(filename, copyname)\n",
    "    \n",
    "    \n",
    "    hdulist = fits.open(copyname, mode='update')\n",
    "    \n",
    "    for ext in xrange(4):\n",
    "        scidata = hdulist[ext].data\n",
    "        sciref = hdulistref[ext].data\n",
    "        scidatashiftedX = ShiftDataX(shift=centroid_shifts2[fn],dataref = sciref,datashift=scidata)\n",
    "        scidatashiftedXY = ShiftData(shift=flexshift_2d[fn],dataref=sciref,datashift=scidatashiftedX)\n",
    "        scidata[:,:] = scidatashiftedXY\n",
    "    \n",
    "    hdulist.flush() \n",
    "                      \n",
    "\n",
    "\n",
    "    hdulist.close()\n",
    "hdulistref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the files have been shifted correctly, background subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tempfile = os.path.splitext(tempfile)[0]\n",
    "    tempfilen = tempfile + '_shifted_bgsub.fits'\n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',filenames[fn])\n",
    "    hdulist = fits.open(filename)\n",
    "    scidata = hdulist[0].data\n",
    "    header = hdulist[0].header\n",
    "    skymodel = hdulist[2].data\n",
    "    scinosky = scidata-skymodel\n",
    "    hdulist.close()\n",
    "    \n",
    "    hdu = fits.PrimaryHDU()\n",
    "    hdu.data = scinosky\n",
    "    hdu.header = header\n",
    "    hdulist = fits.HDUList([hdu])\n",
    "    hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tempfilen))\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And save the standard deviation as a separate fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tempfile = os.path.splitext(tempfile)[0]\n",
    "    tempfilen = tempfile + '_std_shifted.fits'\n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',filenames[fn])\n",
    "    hdulist = fits.open(filename)\n",
    "    header = hdulist[0].header\n",
    "    invvar = hdulist[1].data\n",
    "    std = np.sqrt(1/invvar)\n",
    "    hdulist.close()\n",
    "    \n",
    "    hdu = fits.PrimaryHDU()\n",
    "    hdu.data = std\n",
    "    hdu.header = header\n",
    "    hdulist = fits.HDUList([hdu])\n",
    "    hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tempfilen))\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional (needed in my case since I use DCR to remove cosmic rays):\n",
    "### Replace all the infinities in the standard deviation image by 150 so that we can still remove the cosmic rays\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tempfile = os.path.splitext(tempfile)[0]\n",
    "    filen = tempfile+ '_std_shifted.fits'\n",
    "    tempfilen = tempfile + '_std_infrep_shifted.fits'\n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',filen)\n",
    "    hdulist = fits.open(filename)\n",
    "    header = hdulist[0].header\n",
    "    std = hdulist[0].data\n",
    "    std[np.isinf(std)]=150\n",
    "    hdulist.close()\n",
    "    \n",
    "    hdu = fits.PrimaryHDU()\n",
    "    hdu.data = std\n",
    "    hdu.header = header\n",
    "    hdulist = fits.HDUList([hdu])\n",
    "    hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tempfilen))\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run data through DCR --> called _shifted_bgsub_cleaned.fits \n",
    "\n",
    "## Run error fits through DCR --> called _std_shifted_cleaned.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once DCR has run properly, replace all the 150 values (that had replaced np.inf) with np.inf again so that everything will plot well in DS9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tempfile = os.path.splitext(tempfile)[0]\n",
    "    filen = tempfile+ '_std_infrep_shifted_cleaned.fits'\n",
    "    tempfilen = tempfile + '_std_shifted_cleaned.fits'\n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',filen)\n",
    "    hdulist = fits.open(filename)\n",
    "    header = hdulist[0].header\n",
    "    std = hdulist[0].data\n",
    "    std[std==150]=np.inf\n",
    "    hdulist.close()\n",
    "    \n",
    "    hdu = fits.PrimaryHDU()\n",
    "    hdu.data = std\n",
    "    hdu.header = header\n",
    "    hdulist = fits.HDUList([hdu])\n",
    "    hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tempfilen))\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce normalized coadded image and normalized coadded standard deviation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#produce renormalized coadded image\n",
    "#coadd the images that have had cosmic rays removed:\n",
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "tempname = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted','sci-b150909_1089_shifted_bgsub_cleaned.fits') \n",
    "hdulist2 = fits.open(tempname)\n",
    "scidata0 = hdulist2[0].data\n",
    "temparray = np.zeros_like(scidata0)\n",
    "\n",
    "time = 0\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tfile = os.path.splitext(tempfile)[0]\n",
    "    tfilen = tfile + '_shifted_bgsub_cleaned.fits'\n",
    "    \n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tfilen)\n",
    "    hdulist = fits.open(filename)\n",
    "    scidata = hdulist[0].data\n",
    "    header = hdulist[0].header\n",
    "    time += int(header['TTIME'])\n",
    "    temparray += scidata\n",
    "    hdulist.close()\n",
    "\n",
    "hdu = fits.PrimaryHDU()\n",
    "hdu.data = temparray/time\n",
    "hdu.header = hdulist2[0].header\n",
    "hdulist = fits.HDUList([hdu])\n",
    "#hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','camille_x','Desktop','coadded_LRIS_Slug_noCR_normalized.fits'))\n",
    "hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted','coadded_LRIS_Slug_noCR_normalized.fits'))\n",
    "hdulist.close()\n",
    "hdulist2.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#produce renormalized coadded standard deviation array\n",
    "#coadd the images that have had cosmic rays removed:\n",
    "filenames = np.array(['sci-b150909_1089.fits','sci-b150909_1090.fits','sci-b150909_1091.fits','sci-b150909_1092.fits','sci-b150909_1093.fits','sci-b150909_1094.fits','sci-b150909_1095.fits','sci-b150909_1096.fits','sci-b150909_1097.fits'])\n",
    "\n",
    "tempname = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted','sci-b150909_1089_shifted_bgsub_cleaned.fits') \n",
    "hdulist2 = fits.open(tempname)\n",
    "scidata0 = hdulist2[0].data\n",
    "temparray = np.zeros_like(scidata0)\n",
    "\n",
    "time = 0\n",
    "for fn in xrange(len(filenames)):\n",
    "    tempfile = filenames[fn]\n",
    "    tfile = os.path.splitext(tempfile)[0]\n",
    "    tfilen = tfile + '_std_shifted_cleaned.fits'\n",
    "    \n",
    "    filename = os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted',tfilen)\n",
    "    hdulist = fits.open(filename)\n",
    "    stddata = hdulist[0].data\n",
    "    header = hdulist[0].header\n",
    "    time += int(header['TTIME'])\n",
    "    temparray += np.power(stddata,2)\n",
    "    hdulist.close()\n",
    "\n",
    "hdu = fits.PrimaryHDU()\n",
    "hdu.data = np.sqrt(temparray)/time\n",
    "hdu.header = hdulist2[0].header\n",
    "hdulist = fits.HDUList([hdu])\n",
    "#hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','camille_x','Desktop','coadded_LRIS_Slug_noCR_normalized.fits'))\n",
    "hdulist.writeto(os.path.join(os.path.expanduser('~'),'Dropbox','LowRedux','2015sept','mask_slug_n2_v2','Blue','Science_Slug_shifted','coadded_LRIS_Slug_noCR_normalized_std.fits'))\n",
    "hdulist.close()\n",
    "hdulist2.close()  \n",
    "\n",
    "#note that the coadded image is in e-/s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
